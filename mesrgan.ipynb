{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58188c2a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df05ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party\n",
    "import multiprocessing\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "# First-party\n",
    "from data import *\n",
    "from utils import *\n",
    "from models.mesrgan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08966161",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ccbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME       = \"MESRGAN_T2_ALL_DATA\"\n",
    "TRAIN_STAGE1     = False # TODO: Set to False\n",
    "TRAIN_STAGE2     = True # TODO: Set to False\n",
    "TRAIN_DATA       = [\"data/DIV2K_train_HR\", \"data/Flickr2K\", \"data/OutdoorSceneTrain_v2\"]\n",
    "VAL_DATA         = \"./data/DIV2k_BEST_PICTURES\"\n",
    "DEVICE           = torch.device('cuda:1')\n",
    "N_WORKERS        = 8\n",
    "STAGE1_ITERATIONS= 2e5 \n",
    "STAGE2_ITERATIONS= 2e5   \n",
    "MONITOR_INTERVAL = 1000\n",
    "EXPANSION_FACTOR = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed4ae0c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f159719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean  = [0.4439, 0.4517, 0.4054]\n",
    "data_std   = [0.2738, 0.2607, 0.2856]\n",
    "\n",
    "train_env = {}\n",
    "train_env[\"HR_size\"] = 128\n",
    "train_env[\"LR_size\"] = 128 // 4\n",
    "train_env[\"transform\"] = T.Compose([\n",
    "            T.RandomCrop((train_env[\"HR_size\"], train_env[\"HR_size\"])),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            RandomRotationsTransform([-90, 0, 90]),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "train_env[\"dataset\"]    = ImageDataset(TRAIN_DATA, train_env[\"transform\"])\n",
    "train_env[\"dataloader\"] = DataLoader(train_env[\"dataset\"], batch_size=16, shuffle=True, num_workers=N_WORKERS) \n",
    "\n",
    "val_env = {}\n",
    "val_env[\"HR_size\"] = 1024\n",
    "val_env[\"LR_size\"] = 1024 // 4\n",
    "val_env[\"transform\"] = T.Compose([\n",
    "            T.CenterCrop((val_env[\"HR_size\"], val_env[\"HR_size\"])),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "val_env[\"dataset\"]    = ImageDataset(VAL_DATA, val_env[\"transform\"])\n",
    "val_env[\"dataloader\"] = DataLoader(val_env[\"dataset\"], batch_size=3, shuffle=False, num_workers=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb9ce5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5342925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(t=EXPANSION_FACTOR)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "\n",
    "# Content loss (i.e. L1) for visual similarity\n",
    "content_loss = torch.nn.L1Loss().to(DEVICE)\n",
    "\n",
    "# Perceptual loss (i.e. VGG) to perserve/reconstruct objects/features of original HR image\n",
    "vgg19_model = vgg19(pretrained=True).to(DEVICE)\n",
    "vgg_19_54_model = vgg19_model.features[:35] # \"54 indicates features obtained by the 4th convolution before the 5th maxpooling layer\"\n",
    "vgg_19_54_model.eval()\n",
    "\n",
    "_perceptual_loss = torch.nn.MSELoss(reduction='mean').to(DEVICE)\n",
    "def perceptual_loss(hr_imgs, sr_imgs):\n",
    "    hr_features = vgg_19_54_model(hr_imgs)\n",
    "    sr_features = vgg_19_54_model(sr_imgs)\n",
    "    return _perceptual_loss(hr_features, sr_features)\n",
    "\n",
    "# Adversarial loss for plausibility of image.\n",
    "def rel_disc(x1, x2):\n",
    "    return x1 - x2.mean()\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss(reduction='mean').to(DEVICE)\n",
    "\n",
    "def adversarial_loss(x_r, x_f):\n",
    "    ones = torch.ones((x_r.shape)).to(DEVICE)\n",
    "    zeros = torch.zeros((x_r.shape)).to(DEVICE)\n",
    "    loss = bce_loss(x_r - x_f.mean(), zeros) + bce_loss(x_f - x_r.mean(), ones)\n",
    "    return loss\n",
    "\n",
    "# Discriminator loss used to train the discriminator.\n",
    "def discriminator_loss(x_r, x_f):\n",
    "    ones = torch.ones((x_r.shape)).to(DEVICE)\n",
    "    zeros = torch.zeros((x_r.shape)).to(DEVICE)\n",
    "    loss = bce_loss(x_r - x_f.mean(), ones) + bce_loss(x_f - x_r.mean(), zeros)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed36a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_training_loop(n_iterations):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    writer = SummaryWriter('runs/' + MODEL_NAME + '_stage1')\n",
    "    \n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    #g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=2e5, gamma=0.5)\n",
    "    g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=1e5, gamma=0.5) # Deviates from the paper but 2e5 is too much for us\n",
    "    \n",
    "    n_mini_batches_processed = 0\n",
    "    while n_mini_batches_processed < n_iterations:\n",
    "        \n",
    "        for hr_imgs in train_env[\"dataloader\"]:\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            hr_imgs = hr_imgs.to(DEVICE)\n",
    "            lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "\n",
    "            loss = content_loss(hr_imgs, sr_imgs)\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            g_scheduler.step()\n",
    "            \n",
    "            n_mini_batches_processed += 1        \n",
    "            if n_mini_batches_processed % MONITOR_INTERVAL == 0:\n",
    "                \n",
    "                print(f\"{n_mini_batches_processed} mini-batches done. Content loss: {loss}\")\n",
    "                writer.add_scalar('Content Loss', loss, n_mini_batches_processed)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    hr_imgs = next(iter(val_env['dataloader']))\n",
    "                    hr_imgs = hr_imgs.to(DEVICE)\n",
    "                    lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "                    sr_imgs = generator(lr_imgs)\n",
    "                    \n",
    "                sr_imgs = denormalize(sr_imgs.cpu().detach())\n",
    "                \n",
    "                writer.add_image('SR Butterfly', sr_imgs[0], n_mini_batches_processed)\n",
    "                writer.add_image('SR Food', sr_imgs[1], n_mini_batches_processed)\n",
    "                writer.add_image('SR House', sr_imgs[2], n_mini_batches_processed)\n",
    "                \n",
    "        if n_mini_batches_processed % 20000 == 0:\n",
    "            PATH = \"trained_models/\" + MODEL_NAME + \"_stage1_generator.trch\"\n",
    "            torch.save(generator.state_dict(), PATH)\n",
    "    writer.close()\n",
    "\n",
    "if TRAIN_STAGE1:\n",
    "    #stage1_training_loop(n_iterations=2e5) # The paper doesn't specify an amount\n",
    "    stage1_training_loop(n_iterations=STAGE1_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc382bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"trained_models/\" + MODEL_NAME + \"_stage1_generator.trch\"\n",
    "\n",
    "if TRAIN_STAGE1:\n",
    "    torch.save(generator.state_dict(), PATH)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(PATH))\n",
    "    generator.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch 1000 done. Discriminator loss: 0.00037. Generator loss: 2.05 (perc: 1.93, adv: 24.67, content: 0.13)\n",
      "Mini-Batch 2000 done. Discriminator loss: 0.00897. Generator loss: 2.89 (perc: 2.78, adv: 21.39, content: 0.19)\n",
      "Mini-Batch 3000 done. Discriminator loss: 0.00018. Generator loss: 2.71 (perc: 2.56, adv: 29.43, content: 0.19)\n",
      "Mini-Batch 4000 done. Discriminator loss: 0.02699. Generator loss: 3.42 (perc: 3.31, adv: 21.64, content: 0.21)\n",
      "Mini-Batch 5000 done. Discriminator loss: 0.02797. Generator loss: 3.25 (perc: 3.16, adv: 17.01, content: 0.19)\n",
      "Mini-Batch 6000 done. Discriminator loss: 0.53281. Generator loss: 2.64 (perc: 2.59, adv: 9.50, content: 0.21)\n",
      "Mini-Batch 7000 done. Discriminator loss: 0.00062. Generator loss: 3.29 (perc: 3.19, adv: 19.08, content: 0.19)\n",
      "Mini-Batch 8000 done. Discriminator loss: 0.00145. Generator loss: 3.87 (perc: 3.78, adv: 17.29, content: 0.20)\n",
      "Mini-Batch 9000 done. Discriminator loss: 0.00000. Generator loss: 3.09 (perc: 2.88, adv: 41.28, content: 0.20)\n",
      "Mini-Batch 10000 done. Discriminator loss: 0.01724. Generator loss: 2.52 (perc: 2.40, adv: 23.10, content: 0.15)\n",
      "Mini-Batch 11000 done. Discriminator loss: 0.00002. Generator loss: 3.73 (perc: 3.56, adv: 32.84, content: 0.21)\n",
      "Mini-Batch 12000 done. Discriminator loss: 0.01662. Generator loss: 2.82 (perc: 2.75, adv: 14.44, content: 0.18)\n",
      "Mini-Batch 13000 done. Discriminator loss: 0.00556. Generator loss: 3.48 (perc: 3.39, adv: 18.71, content: 0.16)\n",
      "Mini-Batch 14000 done. Discriminator loss: 0.05181. Generator loss: 3.39 (perc: 3.32, adv: 12.87, content: 0.27)\n",
      "Mini-Batch 15000 done. Discriminator loss: 0.00006. Generator loss: 2.57 (perc: 2.43, adv: 27.83, content: 0.17)\n",
      "Mini-Batch 16000 done. Discriminator loss: 0.00001. Generator loss: 2.32 (perc: 2.17, adv: 29.24, content: 0.14)\n",
      "Mini-Batch 17000 done. Discriminator loss: 0.00005. Generator loss: 2.33 (perc: 2.20, adv: 26.72, content: 0.17)\n",
      "Mini-Batch 18000 done. Discriminator loss: 0.00035. Generator loss: 2.83 (perc: 2.68, adv: 28.44, content: 0.29)\n",
      "Mini-Batch 19000 done. Discriminator loss: 0.00000. Generator loss: 2.36 (perc: 2.14, adv: 43.01, content: 0.18)\n",
      "Mini-Batch 20000 done. Discriminator loss: 2.68576. Generator loss: 2.44 (perc: 2.41, adv: 5.84, content: 0.20)\n",
      "Mini-Batch 21000 done. Discriminator loss: 0.00007. Generator loss: 3.47 (perc: 3.35, adv: 23.99, content: 0.32)\n",
      "Mini-Batch 22000 done. Discriminator loss: 0.00040. Generator loss: 2.85 (perc: 2.73, adv: 22.98, content: 0.20)\n"
     ]
    }
   ],
   "source": [
    "def stage2_training_loop(n_iterations):\n",
    "    torch.cuda.empty_cache()\n",
    "    writer = SummaryWriter('runs/' + MODEL_NAME + '_stage2')\n",
    "    \n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "    g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=5e4, gamma=0.5)\n",
    "    \n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "    \n",
    "    n_mini_batches_processed = 0\n",
    "    while n_mini_batches_processed < n_iterations:\n",
    "        for hr_imgs in train_env[\"dataloader\"]:\n",
    "\n",
    "            hr_imgs = hr_imgs.to(DEVICE)\n",
    "            lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "            \n",
    "            \n",
    "            # Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "\n",
    "            p_loss = perceptual_loss(hr_imgs, sr_imgs)\n",
    "            hr_d = discriminator(hr_imgs)\n",
    "            sr_d = discriminator(sr_imgs)\n",
    "            a_loss = adversarial_loss(hr_d, sr_d)\n",
    "            c_loss = content_loss(hr_imgs, sr_imgs)\n",
    "\n",
    "            lmbd = 5.0e-3\n",
    "            eta  = 1.0e-2\n",
    "            g_loss = p_loss + lmbd * a_loss + eta * c_loss\n",
    "\n",
    "            g_loss.backward()\n",
    "            \n",
    "            g_optimizer.step()\n",
    "            g_scheduler.step()\n",
    "\n",
    "            # Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            hr_d = discriminator(hr_imgs)\n",
    "            sr_d = discriminator(sr_imgs.detach())\n",
    "            d_loss = discriminator_loss(hr_d, sr_d)\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            n_mini_batches_processed += 1        \n",
    "            if n_mini_batches_processed % MONITOR_INTERVAL == 0:\n",
    "                print(f'Mini-Batch {n_mini_batches_processed} done. '\n",
    "                      f'Discriminator loss: {d_loss:.5f}. '\n",
    "                      f'Generator loss: {g_loss:.2f} '\n",
    "                      f'(perc: {p_loss:.2f}, adv: {a_loss:.2f}, content: {c_loss:.2f})'\n",
    "                     )\n",
    "                writer.add_scalar('Content Loss', c_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Perceptual Loss', p_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Adverserial Loss', a_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Discriminator Loss', d_loss, n_mini_batches_processed)\n",
    "                \n",
    "                # Add images\n",
    "                hr_imgs = next(iter(val_env['dataloader']))\n",
    "                hr_imgs = hr_imgs.to(DEVICE)\n",
    "                lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    sr_imgs = generator(lr_imgs)\n",
    "                sr_imgs = denormalize(sr_imgs.cpu().detach())\n",
    "                \n",
    "                writer.add_image('SR Butterfly', sr_imgs[0], n_mini_batches_processed)\n",
    "                writer.add_image('SR Food', sr_imgs[1], n_mini_batches_processed)\n",
    "                writer.add_image('SR House', sr_imgs[2], n_mini_batches_processed)\n",
    "                \n",
    "    torch.save(generator.state_dict(), 'trained_models/' + MODEL_NAME + '_stage2.trch')            \n",
    "    writer.close()\n",
    "    \n",
    "if TRAIN_STAGE2:\n",
    "    #stage2_training_loop(2e5) # The paper doesn't specify an amount\n",
    "    stage2_training_loop(STAGE2_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_PATH = \"trained_models/\" + MODEL_NAME + \"_stage2_generator.trch\"\n",
    "D_PATH = \"trained_models/\" + MODEL_NAME + \"_stage2_discriminator.trch\"\n",
    "\n",
    "if TRAIN_STAGE2:\n",
    "    torch.save(generator.state_dict(), G_PATH)\n",
    "    torch.save(discriminator.state_dict(), D_PATH)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(G_PATH))\n",
    "    discriminator.load_state_dict(torch.load(D_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c7b117",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e14df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hr_imgs = next(iter(train_env['dataloader']))[:4,]\n",
    "    hr_imgs = hr_imgs.to(DEVICE)\n",
    "    lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "    sr_imgs = generator(lr_imgs)\n",
    "    \n",
    "    plot_images(denormalize(lr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(sr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(hr_imgs.cpu().detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7526415",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hr_imgs = next(iter(val_env['dataloader']))\n",
    "    hr_imgs = hr_imgs.to(DEVICE)\n",
    "    lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "    sr_imgs = generator(lr_imgs)\n",
    "    \n",
    "    plot_images(denormalize(lr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(sr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(hr_imgs.cpu().detach()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
