{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48bf632",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0808dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party\n",
    "import multiprocessing\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "# First-party\n",
    "from data import *\n",
    "from utils import *\n",
    "from models.esrgan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a9880",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480d1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME       = \"ESRGAN_ALL_DATA\"\n",
    "TRAIN_STAGE1     = False\n",
    "TRAIN_STAGE2     = True\n",
    "TRAIN_DATA       = [\"data/DIV2K_train_HR\", \"data/Flickr2K\", \"data/OutdoorSceneTrain_v2\"]\n",
    "VAL_DATA         = \"./data/DIV2k_BEST_PICTURES\"\n",
    "DEVICE           = torch.device('cuda:1')\n",
    "N_WORKERS        = 8\n",
    "MONITOR_INTERVAL = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05c363",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef2a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean  = [0.4439, 0.4517, 0.4054]\n",
    "data_std   = [0.2738, 0.2607, 0.2856]\n",
    "\n",
    "train_env = {}\n",
    "train_env[\"HR_size\"] = 128\n",
    "train_env[\"LR_size\"] = 128 // 4\n",
    "train_env[\"transform\"] = T.Compose([\n",
    "            T.RandomCrop((train_env[\"HR_size\"], train_env[\"HR_size\"])),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            RandomRotationsTransform([-90, 0, 90]),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "train_env[\"dataset\"]    = ImageDataset(TRAIN_DATA, train_env[\"transform\"])\n",
    "train_env[\"dataloader\"] = DataLoader(train_env[\"dataset\"], batch_size=16, shuffle=True, num_workers=N_WORKERS) \n",
    "\n",
    "val_env = {}\n",
    "val_env[\"HR_size\"] = 1024\n",
    "val_env[\"LR_size\"] = 1024 // 4\n",
    "val_env[\"transform\"] = T.Compose([\n",
    "            T.CenterCrop((val_env[\"HR_size\"], val_env[\"HR_size\"])),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=data_mean, std=data_std)\n",
    "])\n",
    "val_env[\"dataset\"]    = ImageDataset(VAL_DATA, val_env[\"transform\"])\n",
    "val_env[\"dataloader\"] = DataLoader(val_env[\"dataset\"], batch_size=3, shuffle=False, num_workers=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17584982",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5bd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(DEVICE)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "\n",
    "# Content loss (i.e. L1) for visual similarity\n",
    "content_loss = torch.nn.L1Loss().to(DEVICE)\n",
    "\n",
    "# Perceptual loss (i.e. VGG) to perserve/reconstruct objects/features of original HR image\n",
    "vgg19_model = vgg19(pretrained=True).to(DEVICE)\n",
    "vgg_19_54_model = vgg19_model.features[:35] # \"54 indicates features obtained by the 4th convolution before the 5th maxpooling layer\"\n",
    "vgg_19_54_model.eval()\n",
    "\n",
    "_perceptual_loss = torch.nn.MSELoss(reduction='mean').to(DEVICE)\n",
    "def perceptual_loss(hr_imgs, sr_imgs):\n",
    "    hr_features = vgg_19_54_model(hr_imgs)\n",
    "    sr_features = vgg_19_54_model(sr_imgs)\n",
    "    return _perceptual_loss(hr_features, sr_features)\n",
    "\n",
    "# Adversarial loss for plausibility of image.\n",
    "def rel_disc(x1, x2):\n",
    "    return x1 - x2.mean()\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss(reduction='mean').to(DEVICE)\n",
    "\n",
    "def adversarial_loss(x_r, x_f):\n",
    "    ones = torch.ones((x_r.shape)).to(DEVICE)\n",
    "    zeros = torch.zeros((x_r.shape)).to(DEVICE)\n",
    "    loss = bce_loss(x_r - x_f.mean(), zeros) + bce_loss(x_f - x_r.mean(), ones)\n",
    "    return loss\n",
    "\n",
    "# Discriminator loss used to train the discriminator.\n",
    "def discriminator_loss(x_r, x_f):\n",
    "    ones = torch.ones((x_r.shape)).to(DEVICE)\n",
    "    zeros = torch.zeros((x_r.shape)).to(DEVICE)\n",
    "    loss = bce_loss(x_r - x_f.mean(), ones) + bce_loss(x_f - x_r.mean(), zeros)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ca810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_training_loop(n_iterations):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    writer = SummaryWriter('runs/' + MODEL_NAME + '_stage1')\n",
    "    \n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=2e-4)\n",
    "    #g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=2e5, gamma=0.5)\n",
    "    g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=1e5, gamma=0.5) # Deviates from the paper but 2e5 is too much for us\n",
    "    \n",
    "    n_mini_batches_processed = 0\n",
    "    while n_mini_batches_processed < n_iterations:\n",
    "        \n",
    "        for hr_imgs in train_env[\"dataloader\"]:\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            hr_imgs = hr_imgs.to(DEVICE)\n",
    "            lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "\n",
    "            loss = content_loss(hr_imgs, sr_imgs)\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            g_scheduler.step()\n",
    "            \n",
    "            n_mini_batches_processed += 1        \n",
    "            if n_mini_batches_processed % MONITOR_INTERVAL == 0:\n",
    "                \n",
    "                print(f\"{n_mini_batches_processed} mini-batches done. Content loss: {loss}\")\n",
    "                writer.add_scalar('Content Loss', loss, n_mini_batches_processed)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    hr_imgs = next(iter(val_env['dataloader']))\n",
    "                    hr_imgs = hr_imgs.to(DEVICE)\n",
    "                    lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "                    sr_imgs = generator(lr_imgs)\n",
    "                    \n",
    "                sr_imgs = denormalize(sr_imgs.cpu().detach())\n",
    "                \n",
    "                writer.add_image('SR Butterfly', sr_imgs[0], n_mini_batches_processed)\n",
    "                writer.add_image('SR Food', sr_imgs[1], n_mini_batches_processed)\n",
    "                writer.add_image('SR House', sr_imgs[2], n_mini_batches_processed)\n",
    "                \n",
    "    writer.close()\n",
    "\n",
    "if TRAIN_STAGE1:\n",
    "    stage1_training_loop(n_iterations=2e5) # The paper doesn't specify an amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d28ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"trained_models/\" + MODEL_NAME + \"_stage1_generator.trch\"\n",
    "\n",
    "if TRAIN_STAGE1:\n",
    "    torch.save(generator.state_dict(), PATH)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af707f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch 1000 done. Discriminator loss: 0.00124. Generator loss: 3.29 (perc: 3.18, adv: 22.82, content: 0.14)\n",
      "Mini-Batch 2000 done. Discriminator loss: 0.00849. Generator loss: 2.97 (perc: 2.86, adv: 20.77, content: 0.26)\n",
      "Mini-Batch 3000 done. Discriminator loss: 0.07673. Generator loss: 2.36 (perc: 2.29, adv: 12.92, content: 0.16)\n",
      "Mini-Batch 4000 done. Discriminator loss: 0.00943. Generator loss: 1.68 (perc: 1.60, adv: 16.34, content: 0.12)\n",
      "Mini-Batch 5000 done. Discriminator loss: 0.00111. Generator loss: 4.39 (perc: 4.29, adv: 19.68, content: 0.21)\n",
      "Mini-Batch 6000 done. Discriminator loss: 0.00032. Generator loss: 3.21 (perc: 3.05, adv: 31.91, content: 0.19)\n",
      "Mini-Batch 7000 done. Discriminator loss: 0.00099. Generator loss: 4.45 (perc: 4.33, adv: 22.15, content: 0.20)\n",
      "Mini-Batch 8000 done. Discriminator loss: 0.00065. Generator loss: 3.62 (perc: 3.49, adv: 24.06, content: 0.17)\n",
      "Mini-Batch 9000 done. Discriminator loss: 0.17619. Generator loss: 3.76 (perc: 3.70, adv: 10.51, content: 0.22)\n",
      "Mini-Batch 10000 done. Discriminator loss: 0.03160. Generator loss: 2.81 (perc: 2.73, adv: 16.25, content: 0.19)\n",
      "Mini-Batch 11000 done. Discriminator loss: 0.02177. Generator loss: 4.66 (perc: 4.54, adv: 23.13, content: 0.20)\n",
      "Mini-Batch 12000 done. Discriminator loss: 0.03191. Generator loss: 2.73 (perc: 2.64, adv: 17.88, content: 0.25)\n",
      "Mini-Batch 13000 done. Discriminator loss: 1.20516. Generator loss: 1.95 (perc: 1.93, adv: 3.41, content: 0.16)\n",
      "Mini-Batch 14000 done. Discriminator loss: 0.01317. Generator loss: 3.44 (perc: 3.37, adv: 14.46, content: 0.23)\n",
      "Mini-Batch 15000 done. Discriminator loss: 0.02872. Generator loss: 2.70 (perc: 2.61, adv: 17.56, content: 0.23)\n",
      "Mini-Batch 16000 done. Discriminator loss: 0.00000. Generator loss: 3.29 (perc: 3.06, adv: 46.72, content: 0.20)\n",
      "Mini-Batch 17000 done. Discriminator loss: 0.00000. Generator loss: 2.42 (perc: 2.26, adv: 31.85, content: 0.16)\n",
      "Mini-Batch 18000 done. Discriminator loss: 0.04514. Generator loss: 2.41 (perc: 2.34, adv: 14.64, content: 0.20)\n",
      "Mini-Batch 19000 done. Discriminator loss: 0.00201. Generator loss: 2.94 (perc: 2.86, adv: 15.91, content: 0.16)\n",
      "Mini-Batch 20000 done. Discriminator loss: 0.00017. Generator loss: 2.58 (perc: 2.48, adv: 21.12, content: 0.20)\n",
      "Mini-Batch 21000 done. Discriminator loss: 0.00291. Generator loss: 2.45 (perc: 2.34, adv: 20.85, content: 0.15)\n",
      "Mini-Batch 22000 done. Discriminator loss: 0.19431. Generator loss: 3.69 (perc: 3.60, adv: 16.22, content: 0.18)\n",
      "Mini-Batch 23000 done. Discriminator loss: 0.00182. Generator loss: 3.68 (perc: 3.58, adv: 18.73, content: 0.19)\n",
      "Mini-Batch 24000 done. Discriminator loss: 0.00001. Generator loss: 3.48 (perc: 3.33, adv: 30.11, content: 0.29)\n",
      "Mini-Batch 25000 done. Discriminator loss: 0.00014. Generator loss: 2.24 (perc: 2.11, adv: 24.59, content: 0.15)\n",
      "Mini-Batch 26000 done. Discriminator loss: 0.00000. Generator loss: 3.02 (perc: 2.85, adv: 33.24, content: 0.17)\n",
      "Mini-Batch 27000 done. Discriminator loss: 0.00055. Generator loss: 2.38 (perc: 2.25, adv: 24.12, content: 0.18)\n",
      "Mini-Batch 28000 done. Discriminator loss: 0.02038. Generator loss: 3.29 (perc: 3.23, adv: 11.98, content: 0.23)\n",
      "Mini-Batch 29000 done. Discriminator loss: 0.00000. Generator loss: 2.45 (perc: 2.28, adv: 33.69, content: 0.19)\n",
      "Mini-Batch 30000 done. Discriminator loss: 0.00290. Generator loss: 2.83 (perc: 2.73, adv: 19.41, content: 0.18)\n",
      "Mini-Batch 31000 done. Discriminator loss: 0.14703. Generator loss: 2.72 (perc: 2.64, adv: 15.93, content: 0.20)\n",
      "Mini-Batch 32000 done. Discriminator loss: 1.47319. Generator loss: 2.71 (perc: 2.69, adv: 4.13, content: 0.21)\n",
      "Mini-Batch 33000 done. Discriminator loss: 0.00000. Generator loss: 3.96 (perc: 3.79, adv: 34.19, content: 0.22)\n",
      "Mini-Batch 34000 done. Discriminator loss: 0.88169. Generator loss: 3.66 (perc: 3.63, adv: 4.66, content: 0.19)\n",
      "Mini-Batch 35000 done. Discriminator loss: 0.00000. Generator loss: 3.46 (perc: 3.21, adv: 48.86, content: 0.17)\n",
      "Mini-Batch 36000 done. Discriminator loss: 0.01353. Generator loss: 4.42 (perc: 4.34, adv: 15.66, content: 0.24)\n",
      "Mini-Batch 37000 done. Discriminator loss: 0.00000. Generator loss: 2.28 (perc: 2.10, adv: 36.60, content: 0.11)\n",
      "Mini-Batch 38000 done. Discriminator loss: 0.00000. Generator loss: 3.45 (perc: 3.30, adv: 30.69, content: 0.18)\n",
      "Mini-Batch 39000 done. Discriminator loss: 0.00001. Generator loss: 2.65 (perc: 2.50, adv: 29.39, content: 0.17)\n",
      "Mini-Batch 40000 done. Discriminator loss: 0.00001. Generator loss: 2.98 (perc: 2.82, adv: 32.53, content: 0.24)\n",
      "Mini-Batch 41000 done. Discriminator loss: 0.00232. Generator loss: 2.14 (perc: 2.05, adv: 19.38, content: 0.17)\n",
      "Mini-Batch 42000 done. Discriminator loss: 0.17814. Generator loss: 3.24 (perc: 3.19, adv: 10.59, content: 0.25)\n",
      "Mini-Batch 43000 done. Discriminator loss: 0.00001. Generator loss: 2.36 (perc: 2.18, adv: 36.89, content: 0.26)\n",
      "Mini-Batch 44000 done. Discriminator loss: 0.00000. Generator loss: 3.17 (perc: 2.99, adv: 34.84, content: 0.19)\n",
      "Mini-Batch 45000 done. Discriminator loss: 0.00086. Generator loss: 4.43 (perc: 4.33, adv: 19.42, content: 0.23)\n",
      "Mini-Batch 46000 done. Discriminator loss: 0.00879. Generator loss: 1.80 (perc: 1.65, adv: 28.57, content: 0.17)\n",
      "Mini-Batch 47000 done. Discriminator loss: 0.02028. Generator loss: 2.45 (perc: 2.39, adv: 11.84, content: 0.24)\n",
      "Mini-Batch 48000 done. Discriminator loss: 0.00464. Generator loss: 3.30 (perc: 3.21, adv: 19.00, content: 0.27)\n",
      "Mini-Batch 49000 done. Discriminator loss: 1.41171. Generator loss: 1.38 (perc: 1.34, adv: 8.21, content: 0.14)\n",
      "Mini-Batch 50000 done. Discriminator loss: 0.01241. Generator loss: 3.48 (perc: 3.41, adv: 15.02, content: 0.33)\n",
      "Mini-Batch 51000 done. Discriminator loss: 0.00001. Generator loss: 2.69 (perc: 2.55, adv: 27.03, content: 0.28)\n",
      "Mini-Batch 52000 done. Discriminator loss: 0.00031. Generator loss: 2.14 (perc: 2.02, adv: 22.53, content: 0.20)\n",
      "Mini-Batch 53000 done. Discriminator loss: 0.00018. Generator loss: 2.42 (perc: 2.29, adv: 25.85, content: 0.25)\n",
      "Mini-Batch 54000 done. Discriminator loss: 0.00120. Generator loss: 1.65 (perc: 1.55, adv: 18.13, content: 0.22)\n",
      "Mini-Batch 55000 done. Discriminator loss: 0.00004. Generator loss: 2.44 (perc: 2.33, adv: 22.78, content: 0.21)\n",
      "Mini-Batch 56000 done. Discriminator loss: 0.00064. Generator loss: 3.77 (perc: 3.67, adv: 20.67, content: 0.23)\n",
      "Mini-Batch 57000 done. Discriminator loss: 0.01533. Generator loss: 2.87 (perc: 2.80, adv: 14.35, content: 0.19)\n",
      "Mini-Batch 58000 done. Discriminator loss: 0.00019. Generator loss: 3.48 (perc: 3.36, adv: 23.16, content: 0.21)\n",
      "Mini-Batch 59000 done. Discriminator loss: 0.00001. Generator loss: 2.83 (perc: 2.69, adv: 27.23, content: 0.27)\n",
      "Mini-Batch 60000 done. Discriminator loss: 0.00039. Generator loss: 2.59 (perc: 2.47, adv: 24.09, content: 0.16)\n",
      "Mini-Batch 61000 done. Discriminator loss: 0.44065. Generator loss: 1.40 (perc: 1.37, adv: 5.50, content: 0.14)\n",
      "Mini-Batch 62000 done. Discriminator loss: 0.00005. Generator loss: 4.76 (perc: 4.63, adv: 25.93, content: 0.21)\n",
      "Mini-Batch 63000 done. Discriminator loss: 0.00000. Generator loss: 2.69 (perc: 2.52, adv: 32.06, content: 0.23)\n",
      "Mini-Batch 64000 done. Discriminator loss: 0.00000. Generator loss: 2.95 (perc: 2.72, adv: 44.46, content: 0.22)\n",
      "Mini-Batch 65000 done. Discriminator loss: 0.00001. Generator loss: 2.63 (perc: 2.50, adv: 27.06, content: 0.17)\n",
      "Mini-Batch 66000 done. Discriminator loss: 0.00002. Generator loss: 4.09 (perc: 3.92, adv: 33.60, content: 0.20)\n",
      "Mini-Batch 67000 done. Discriminator loss: 0.00076. Generator loss: 3.10 (perc: 3.01, adv: 18.84, content: 0.15)\n",
      "Mini-Batch 68000 done. Discriminator loss: 0.00002. Generator loss: 3.16 (perc: 3.02, adv: 28.06, content: 0.25)\n",
      "Mini-Batch 69000 done. Discriminator loss: 0.00000. Generator loss: 2.55 (perc: 2.40, adv: 29.42, content: 0.21)\n",
      "Mini-Batch 70000 done. Discriminator loss: 0.00000. Generator loss: 3.10 (perc: 2.82, adv: 56.73, content: 0.16)\n",
      "Mini-Batch 71000 done. Discriminator loss: 0.00000. Generator loss: 3.09 (perc: 2.88, adv: 41.92, content: 0.18)\n",
      "Mini-Batch 72000 done. Discriminator loss: 0.01954. Generator loss: 1.41 (perc: 1.34, adv: 13.15, content: 0.19)\n",
      "Mini-Batch 73000 done. Discriminator loss: 0.00046. Generator loss: 2.89 (perc: 2.79, adv: 18.94, content: 0.14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch 74000 done. Discriminator loss: 0.27603. Generator loss: 2.98 (perc: 2.93, adv: 9.99, content: 0.30)\n",
      "Mini-Batch 75000 done. Discriminator loss: 0.00007. Generator loss: 2.74 (perc: 2.61, adv: 25.65, content: 0.24)\n",
      "Mini-Batch 76000 done. Discriminator loss: 0.00305. Generator loss: 2.83 (perc: 2.74, adv: 17.45, content: 0.22)\n",
      "Mini-Batch 77000 done. Discriminator loss: 0.04364. Generator loss: 2.54 (perc: 2.44, adv: 19.91, content: 0.19)\n",
      "Mini-Batch 78000 done. Discriminator loss: 0.00000. Generator loss: 2.90 (perc: 2.71, adv: 37.83, content: 0.19)\n",
      "Mini-Batch 79000 done. Discriminator loss: 0.00016. Generator loss: 1.59 (perc: 1.43, adv: 31.50, content: 0.17)\n",
      "Mini-Batch 80000 done. Discriminator loss: 0.10708. Generator loss: 1.98 (perc: 1.93, adv: 9.62, content: 0.15)\n",
      "Mini-Batch 81000 done. Discriminator loss: 0.00151. Generator loss: 2.22 (perc: 2.12, adv: 20.32, content: 0.17)\n",
      "Mini-Batch 82000 done. Discriminator loss: 0.00000. Generator loss: 3.64 (perc: 3.47, adv: 33.68, content: 0.19)\n",
      "Mini-Batch 83000 done. Discriminator loss: 0.00001. Generator loss: 4.83 (perc: 4.68, adv: 30.03, content: 0.26)\n",
      "Mini-Batch 84000 done. Discriminator loss: 0.01597. Generator loss: 2.07 (perc: 1.97, adv: 20.41, content: 0.14)\n",
      "Mini-Batch 85000 done. Discriminator loss: 0.00039. Generator loss: 2.80 (perc: 2.68, adv: 23.58, content: 0.20)\n",
      "Mini-Batch 86000 done. Discriminator loss: 0.00005. Generator loss: 2.96 (perc: 2.82, adv: 27.61, content: 0.19)\n",
      "Mini-Batch 87000 done. Discriminator loss: 0.00357. Generator loss: 2.91 (perc: 2.77, adv: 27.86, content: 0.17)\n",
      "Mini-Batch 88000 done. Discriminator loss: 0.02317. Generator loss: 3.81 (perc: 3.74, adv: 12.75, content: 0.30)\n",
      "Mini-Batch 89000 done. Discriminator loss: 0.00697. Generator loss: 2.54 (perc: 2.44, adv: 19.81, content: 0.12)\n",
      "Mini-Batch 90000 done. Discriminator loss: 0.01175. Generator loss: 2.66 (perc: 2.60, adv: 12.85, content: 0.22)\n",
      "Mini-Batch 91000 done. Discriminator loss: 0.00008. Generator loss: 3.22 (perc: 3.10, adv: 22.92, content: 0.22)\n",
      "Mini-Batch 92000 done. Discriminator loss: 0.00326. Generator loss: 3.33 (perc: 3.19, adv: 28.64, content: 0.22)\n",
      "Mini-Batch 93000 done. Discriminator loss: 0.00000. Generator loss: 3.75 (perc: 3.54, adv: 42.89, content: 0.23)\n",
      "Mini-Batch 94000 done. Discriminator loss: 2.46532. Generator loss: 2.76 (perc: 2.74, adv: 1.93, content: 0.25)\n",
      "Mini-Batch 95000 done. Discriminator loss: 0.00028. Generator loss: 2.94 (perc: 2.82, adv: 24.41, content: 0.23)\n",
      "Mini-Batch 96000 done. Discriminator loss: 0.00000. Generator loss: 2.98 (perc: 2.79, adv: 37.62, content: 0.19)\n",
      "Mini-Batch 97000 done. Discriminator loss: 0.00006. Generator loss: 2.56 (perc: 2.43, adv: 26.03, content: 0.18)\n",
      "Mini-Batch 98000 done. Discriminator loss: 0.00000. Generator loss: 2.20 (perc: 2.03, adv: 32.44, content: 0.19)\n",
      "Mini-Batch 99000 done. Discriminator loss: 0.00360. Generator loss: 3.23 (perc: 3.14, adv: 17.99, content: 0.19)\n",
      "Mini-Batch 100000 done. Discriminator loss: 0.00988. Generator loss: 2.57 (perc: 2.50, adv: 13.06, content: 0.22)\n",
      "Mini-Batch 101000 done. Discriminator loss: 0.00002. Generator loss: 2.58 (perc: 2.44, adv: 26.47, content: 0.19)\n"
     ]
    }
   ],
   "source": [
    "def stage2_training_loop(n_iterations):\n",
    "    torch.cuda.empty_cache()\n",
    "    writer = SummaryWriter('runs/' + MODEL_NAME + '_stage2')\n",
    "    \n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "    g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=5e4, gamma=0.5)\n",
    "    \n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "    \n",
    "    n_mini_batches_processed = 0\n",
    "    while n_mini_batches_processed < n_iterations:\n",
    "        for hr_imgs in train_env[\"dataloader\"]:\n",
    "\n",
    "            hr_imgs = hr_imgs.to(DEVICE)\n",
    "            lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "            \n",
    "            \n",
    "            # Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "\n",
    "            p_loss = perceptual_loss(hr_imgs, sr_imgs)\n",
    "            hr_d = discriminator(hr_imgs)\n",
    "            sr_d = discriminator(sr_imgs)\n",
    "            a_loss = adversarial_loss(hr_d, sr_d)\n",
    "            c_loss = content_loss(hr_imgs, sr_imgs)\n",
    "\n",
    "            lmbd = 5.0e-3\n",
    "            eta  = 1.0e-2\n",
    "            g_loss = p_loss + lmbd * a_loss + eta * c_loss\n",
    "\n",
    "            g_loss.backward()\n",
    "            \n",
    "            g_optimizer.step()\n",
    "            g_scheduler.step()\n",
    "\n",
    "            # Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            hr_d = discriminator(hr_imgs)\n",
    "            sr_d = discriminator(sr_imgs.detach())\n",
    "            d_loss = discriminator_loss(hr_d, sr_d)\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            n_mini_batches_processed += 1        \n",
    "            if n_mini_batches_processed % MONITOR_INTERVAL == 0:\n",
    "                print(f'Mini-Batch {n_mini_batches_processed} done. '\n",
    "                      f'Discriminator loss: {d_loss:.5f}. '\n",
    "                      f'Generator loss: {g_loss:.2f} '\n",
    "                      f'(perc: {p_loss:.2f}, adv: {a_loss:.2f}, content: {c_loss:.2f})'\n",
    "                     )\n",
    "                writer.add_scalar('Content Loss', c_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Perceptual Loss', p_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Adverserial Loss', a_loss, n_mini_batches_processed)\n",
    "                writer.add_scalar('Discriminator Loss', d_loss, n_mini_batches_processed)\n",
    "                \n",
    "                # Add images\n",
    "                hr_imgs = next(iter(val_env['dataloader']))\n",
    "                hr_imgs = hr_imgs.to(DEVICE)\n",
    "                lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    sr_imgs = generator(lr_imgs)\n",
    "                sr_imgs = denormalize(sr_imgs.cpu().detach())\n",
    "                \n",
    "                writer.add_image('SR Butterfly', sr_imgs[0], n_mini_batches_processed)\n",
    "                writer.add_image('SR Food', sr_imgs[1], n_mini_batches_processed)\n",
    "                writer.add_image('SR House', sr_imgs[2], n_mini_batches_processed)\n",
    "                \n",
    "    torch.save(generator.state_dict(), 'trained_models/' + MODEL_NAME + '_stage2.trch')            \n",
    "    writer.close()\n",
    "    \n",
    "if TRAIN_STAGE2:\n",
    "    stage2_training_loop(2e5) # The paper doesn't specify an amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_PATH = \"trained_models/\" + MODEL_NAME + \"_stage2_generator.trch\"\n",
    "D_PATH = \"trained_models/\" + MODEL_NAME + \"_stage2_discriminator.trch\"\n",
    "\n",
    "if TRAIN_STAGE2:\n",
    "    torch.save(generator.state_dict(), G_PATH)\n",
    "    torch.save(discriminator.state_dict(), D_PATH)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(G_PATH))\n",
    "    discriminator.load_state_dict(torch.load(D_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d63a4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hr_imgs = next(iter(train_env['dataloader']))[:4,]\n",
    "    hr_imgs = hr_imgs.to(DEVICE)\n",
    "    lr_imgs = F.interpolate(hr_imgs, size=(train_env[\"LR_size\"], train_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "    sr_imgs = generator(lr_imgs)\n",
    "    \n",
    "    plot_images(denormalize(lr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(sr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(hr_imgs.cpu().detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b077d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hr_imgs = next(iter(val_env['dataloader']))\n",
    "    hr_imgs = hr_imgs.to(DEVICE)\n",
    "    lr_imgs = F.interpolate(hr_imgs, size=(val_env[\"LR_size\"], val_env[\"LR_size\"]), mode='bicubic', align_corners=False)\n",
    "    sr_imgs = generator(lr_imgs)\n",
    "    \n",
    "    plot_images(denormalize(lr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(sr_imgs.cpu().detach()))\n",
    "    plot_images(denormalize(hr_imgs.cpu().detach()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
